# ğŸ‘‹ Hi there, I'm Anil Kumar

**Machine Learning Engineer | Computer Vision & Multimodal AI Specialist**  
Building scalable ML systems that bridge **computer vision and language understanding** for e-commerce, retail, and content platforms.

---

## ğŸ§  About Me

- ğŸ“ **B.Tech + M.Tech in Computer Science**
- ğŸ’¼ **8+ years of experience** in Machine Learning & Deep Learning
- ğŸ—ï¸ Experienced in **end-to-end ML project execution**: from problem discovery, data curation, model development, to scalable deployment.
  <!-- - ğŸ“Š Spent 70â€“80% of my time on **data curation and preparation**, ensuring clean and relevant datasets for high-performing models. -->

---

## ğŸ”¥ Key Domains

- ğŸ§  Classification, Detection, Recognition
- ğŸ–¼ï¸ Vision-Language Multimodal Models
- ğŸ¥ Video AI and Audio-Visual Understanding
- ğŸ§‘â€ğŸ¤â€ğŸ§‘ Face Recognition & Clustering
- ğŸ§µ Self-Supervised Learning & Transformers

---

## ğŸš€ Projects & Solutions

### ğŸ›ï¸ E-Commerce & Fashion AI

| Project | Description |
|--------|-------------|
| ğŸ‘— **AI Stylist (LLaMA Fine-Tuning)** | Outfit generation and completion using fine-tuned LLaMA on fashion datasets. |
| ğŸ§¥ **Clothing Part Detection** | Detects clothing parts like top, bottum, and full part of clothing using object detection. |
| ğŸ¬ **Shoppable Video Injection** | Detects fashion items in videos and links them to e-commerce catalogs. |
| ğŸ‘— **Visual Similarity Search** | Uses CLIP-based embeddings to find visually similar items. |
| ğŸ§  **Fashion Recommender** | Recommends complementary clothing items using co-occurrence and visual signals. |
| ğŸ” **Image Captioning for Fashion** | Generates detailed product captions using image-text pairs. |
| ğŸ›ï¸ **Fashion Image Classification** | Categorizes fashion products into types, styles, and materials. |

---

### ğŸ¥ Video Intelligence & Content Understanding

| Project | Description |
|--------|-------------|
| ğŸ›¡ï¸ **Content Moderation** | Detects unsafe visual/audio content in real-time videos. |
| ğŸ–¼ï¸ **AI Thumbnail Generator** | Generates high-engagement thumbnails from video frames using saliency + aesthetics. |
| ğŸ¥ **Video Classification** | Classifies videos based on topic, activity, or content type using I3D & Transformers. |
| ğŸ§‘â€ğŸ¦° **Face Recognition System** | Identifies and clusters faces across frames and videos with tracking and ArcFace embeddings. |
| ğŸ¥ **Video Engagement prediction** | Predict engagement score for short videos for different models for different durations. |
| ğŸ§  **Video Retrieval & Similarity Search** | Retrieves similar videos using multimodal embeddings (visual + audio). |
| ğŸï¸ **Scene & Logo Detection** | Detects brand logos and segments scenes for campaign analysis. |
| ğŸ” **Video Feature Extraction System** | Extracts temporal visual features using I3D, audio features via VGGish, and fuses them. |
| ğŸ›‘ **Content Moderation Pipeline** | Full-stack system for video flagging using detection, OCR, audio, and vision. |
| ğŸ‘¥ **Self-Supervised Face Clustering** | Clusters faces in video using contrastive learning + clustering with FAISS + DeepFace. |

---

### ğŸ”Š Audio & Text Understanding

| Project | Description |
|--------|-------------|
| ğŸ—£ï¸ **Audio Classification** | Classifies audio streams using VGGish and temporal modeling. |
| ğŸ§ **Text Feature Extraction** | Extracts rich contextual embeddings using BERT-Model. |
| ğŸ˜Š **Sentiment Analysis** | Detects user sentiment from product reviews. |

---

### âš™ï¸ Core ML & R&D Work

| Project | Description |
|--------|-------------|
| ğŸ”¢ **Digit Classification** | Classic CNN pipeline for MNIST-style digit recognition. |
| ğŸ§ª **Model Comparison & Metrics** | Benchmarked models using F1, ROC-AUC, precision/recall across tasks. |
| ğŸ§¼ **Data Cleaning & Curation Tools** | Built semi-automated data annotation and deduplication pipelines. |
| ğŸ§µ **Vision Transformer with MAE** | Used masked autoencoders for unsupervised pretraining on large vision datasets. |
| ğŸ¤– **Object Detection & Classification** | Trained YOLO and Faster-RCNN models for retail and surveillance. |
| ğŸ–¼ï¸ **CLIP-based Feature Embeddings** | Used CLIP to unify vision and text space for similarity and search. |

---



